{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from wikitools import wiki, category, api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Article:\n",
    "    \n",
    "    def __init__(self, title, body, links=None, categories=None, templates=None):\n",
    "        self.title = title\n",
    "        self.body = body\n",
    "        self.links = links\n",
    "        self.categories = categories\n",
    "        self.templates = templates\n",
    "        \n",
    "    def to_json(self):\n",
    "        result = dict()\n",
    "        result.update({\"title\": self.title})\n",
    "        result.update({\"body\": self.body})\n",
    "        \n",
    "        links = list()\n",
    "        for l in self.links:\n",
    "            links.append({\"link\": l[0], \"anchor\": l[1]})\n",
    "       \n",
    "        result.update({\"links\": links})   \n",
    "        \n",
    "        categories = list()\n",
    "        for c in self.categories:\n",
    "            categories.append(c)\n",
    "       \n",
    "        result.update({\"categories\": categories})\n",
    "        \n",
    "        templates = list()\n",
    "        for t in self.templates:\n",
    "            templates.append(t)\n",
    "        \n",
    "        result.update({\"templates\": templates})\n",
    "        return json.dumps(result, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def link_finder(content_string):\n",
    "    links = list()\n",
    "    for i,j in re.findall(r'\\[\\[([^|\\]]*\\|)?([^\\]]+)\\]\\]',content_string):\n",
    "        if len(i) == 0:\n",
    "            links.append((j, j))\n",
    "        elif u'#' not in i :\n",
    "            links.append((j, i[:-1]))\n",
    "        elif u'#' in i:\n",
    "            new_i = i[:i.index(u'#')]\n",
    "            links.append((j, new_i))\n",
    "    links = [l for l in links if u'|' not in l[1] and u'Category:' not in l[1] and u'File:' not in l[1]]\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# utils\n",
    "def convert_to_datetime(string):\n",
    "    dt = datetime.datetime.strptime(string,'%Y-%m-%dT%H:%M:%SZ')\n",
    "    return dt\n",
    "    \n",
    "def convert_from_datetime(dt):\n",
    "    string = dt.strftime('%Y%m%d%H%M%S')\n",
    "    return string\n",
    "\n",
    "def cast_to_unicode(string):\n",
    "    if isinstance(string,str):\n",
    "        try:\n",
    "            string2 = string.decode('utf8')\n",
    "        except:\n",
    "            try:\n",
    "                string2 = string.decode('latin1')\n",
    "            except:\n",
    "                print \"Some messed up encoding here\"\n",
    "    elif isinstance(string,unicode):\n",
    "        string2 = string\n",
    "    return string2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rename_on_redirect(article_title,lang='en'):\n",
    "    result = query_wikipedia({'titles': article_title,\n",
    "                              'prop': 'info',\n",
    "                              'action': 'query',\n",
    "                              'redirects': 'True'},lang)\n",
    "    if 'redirects' in result.keys() and 'pages' in result.keys():\n",
    "        article_title = result['redirects'][0]['to']\n",
    "    return article_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def query_wikipedia(query_params, lang=\"en\"):\n",
    "    site = wiki.Wiki(url='http://'+lang+'.wikipedia.org/w/api.php')\n",
    "    request = api.APIRequest(site, query_params)\n",
    "    result = request.query()\n",
    "    return result\n",
    "#     return result[query_params['action']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_category_members(category_name, depth, lang='en'):\n",
    "    articles = []\n",
    "    if depth < 0:\n",
    "        return articles\n",
    "    continue_query = \"\"\n",
    "    while (True):\n",
    "        #Begin crawling articles in category\n",
    "        res = query_wikipedia({'list': 'categorymembers',\n",
    "                                   'cmtitle': category_name,\n",
    "                                   'cmtype': 'page',\n",
    "                                   'cmlimit': '500',\n",
    "                                   'action': 'query',\n",
    "                                   'cmcontinue': continue_query},lang) \n",
    "        if 'continue' not in res.keys():\n",
    "            break\n",
    "        else:\n",
    "            continue_query = res['continue']['cmcontinue']\n",
    "        results = res['query']\n",
    "        if 'categorymembers' in results.keys() and len(results['categorymembers']) > 0:\n",
    "            for i, page in enumerate(results['categorymembers']):\n",
    "                article = page['title']\n",
    "                articles.append(article)\n",
    "\n",
    "        # Begin crawling subcategories\n",
    "        results = query_wikipedia({'list': 'categorymembers',\n",
    "                                       'cmtitle': category_name,\n",
    "                                       'cmtype': 'subcat',\n",
    "                                       'cmlimit': '500',\n",
    "                                       'action': 'query',\n",
    "                                       'cmcontinue': continue_query},lang)\n",
    "        subcategories = []\n",
    "        if 'categorymembers' in results.keys() and len(results['categorymembers']) > 0:\n",
    "            for i, category in enumerate(results['categorymembers']):\n",
    "                cat_title = category['title']\n",
    "                subcategories.append(cat_title)\n",
    "        for category in subcategories:\n",
    "            articles += get_category_members(category,depth-1)      \n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_page_content(page_title,lang):\n",
    "    article_title = rename_on_redirect(page_title, lang)\n",
    "    revisions_dict = dict()\n",
    "    result = query_wikipedia({'titles': article_title,\n",
    "                              'prop': 'revisions',\n",
    "                              'rvprop': 'ids|content',\n",
    "                              'rvlimit': '5000',\n",
    "                              'action': 'query'},lang)\n",
    "    if result and 'pages' in result.keys():\n",
    "        page_number = result['pages'].keys()[0]\n",
    "        try:\n",
    "            revisions = result['pages'][page_number]['revisions']\n",
    "            for revision in revisions:\n",
    "                rev = dict()\n",
    "                rev['pageid'] = page_number\n",
    "                rev['title'] = result['pages'][page_number]['title']\n",
    "                rev['content'] = revision.get('*',unicode()) # Sometimes content hidden, return with empty unicode string\n",
    "                rev['revid'] = revision['revid']\n",
    "                revisions_dict[revision['revid']] = rev\n",
    "        except:\n",
    "            pass\n",
    "    return revisions_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_page_categories(page_title, lang='en'):\n",
    "    page_title = rename_on_redirect(page_title, lang)\n",
    "    results = query_wikipedia({'prop': 'categories',\n",
    "                               'titles': page_title,\n",
    "                               'cllimit': '500',\n",
    "                               'clshow':'!hidden',\n",
    "                               'action': 'query'},lang)\n",
    "    if 'pages' in results.keys():\n",
    "        page_number = results['pages'].keys()[0]\n",
    "        categories = results['pages'][page_number]['categories']\n",
    "        categories = [i['title'] for i in categories]\n",
    "        cat = list()\n",
    "        for c in categories:\n",
    "            res = False\n",
    "            r = re.compile(u'Category:(.*)')\n",
    "            cat.append(re.findall(r, c)[0])\n",
    "    else:\n",
    "        print u\"{0} not found in category results\".format(page_title)\n",
    "    return cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_page_templates(page_title, lang):\n",
    "    page_title = cast_to_unicode(page_title)\n",
    "    page_title = rename_on_redirect(page_title, lang)\n",
    "    result = query_wikipedia({'titles': page_title,\n",
    "                              'prop': 'templates',\n",
    "                              'tllimit': '500',\n",
    "                              'action': 'query'},lang)\n",
    "    if 'pages' in result.keys():\n",
    "        page_id = result['pages'].keys()[0]\n",
    "        templates = list()\n",
    "        if 'templates' in result['pages'][page_id].keys():\n",
    "            templates = [i['title'] for i in result['pages'][page_id]['templates']]\n",
    "    return templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_article(title, lang=\"en\"):\n",
    "    result = None\n",
    "    content = get_page_content(title, lang)\n",
    "    # we take only last revision\n",
    "    rev_key = content.keys()[0]\n",
    "    categories = get_page_categories(title, lang)\n",
    "    templates = get_page_templates(title, lang)\n",
    "    result = Article(content[rev_key][\"title\"], \n",
    "                          content[rev_key][\"content\"],\n",
    "                          link_finder(content[rev_key][\"content\"]),\n",
    "                          categories,\n",
    "                          templates)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server lag, sleeping for 7 seconds\n",
      "Server lag, sleeping for 6 seconds\n"
     ]
    }
   ],
   "source": [
    "dis_pages = get_category_members(\"Category:All_disambiguation_pages\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('disambiguation_pages.csv', 'w') as f:\n",
    "    f.write(codecs.encode(\"\\n\".join(dis_pages), 'utf-8'))\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
